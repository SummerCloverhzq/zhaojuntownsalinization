import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from lightgbm import LGBMRegressor, plot_importance
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import shap

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

file_path = 'file.csv'
data = pd.read_csv(file_path, encoding='gbk')
data.dropna(inplace=True)
data.drop_duplicates(inplace=True)
data['Classification of land use'] = data['Classification of land use'].astype(int)
data['lon'] = data['Longitude']
data['lat'] = data['Latitude']
data['lon2'] = data['lon'] ** 2
data['lat2'] = data['lat'] ** 2
data['lon_lat'] = data['lon'] * data['lat']
data['sin_lat'] = np.sin(np.radians(data['lat']))
data['cos_lat'] = np.cos(np.radians(data['lat']))

y = data['0_10']
features = ['LST', 'DEM', 'PET', 'ET', 'Classification of land use',
            'lon', 'lat', 'lon2', 'lat2', 'lon_lat', 'sin_lat', 'cos_lat',
            'NDSI', 'EBSI', 'EVI2', 'BSI', 'NDVI']
X = data[features]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=65
)
kf = KFold(n_splits=10, shuffle=True, random_state=65)
lgb = LGBMRegressor(
    n_estimators=200,
    max_depth=5,
    learning_rate=0.1,
    random_state=65
)
lgb.fit(X_train, y_train)

y_pred = lgb.predict(X_test)
train_pred = lgb.predict(X_train)

print(f"Test MSE: {mean_squared_error(y_test, y_pred):.4f}")
print(f"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")
print(f"Test MAE: {mean_absolute_error(y_test, y_pred):.4f}")
print(f"Test R²: {r2_score(y_test, y_pred):.4f}")
print(f"Train R²: {r2_score(y_train, train_pred):.4f}")
print(f"Train MSE: {mean_squared_error(y_train, train_pred):.4f}")
print(f"Train RMSE: {np.sqrt(mean_squared_error(y_train, train_pred)):.4f}")
print(f"Train MAE: {mean_absolute_error(y_train, train_pred):.4f}")

plt.figure(figsize=(8, 6))
plot_importance(lgb, max_num_features=15, height=0.5)
plt.title("LightGBM Feature Importance")
plt.show()

plt.figure(figsize=(6, 4))
plt.plot(range(len(y_test)), y_test.values, 'o-', label='True Values')
plt.plot(range(len(y_pred)), y_pred, 'o-', label='Predicted Values')
plt.xlabel('Test Sample Index')
plt.ylabel('ASD Index')
plt.title('True vs Predicted Values')
plt.legend()
plt.show()

plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred, alpha=0.7, label='Test Data')
plt.plot([y_test.min(), y_test.max()], 
         [y_test.min(), y_test.max()], 
         'r--', lw=2, label='Perfect Prediction Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('Scatter Plot: True vs Predicted')
plt.legend()
plt.show()

explainer = shap.Explainer(lgb)
shap_values = explainer(X_test)
shap.summary_plot(shap_values, X_test, feature_names=features)
